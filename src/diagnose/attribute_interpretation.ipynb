{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import clip\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from models import Linear\n",
    "\n",
    "clip_model_name = \"ViT-B/32\"\n",
    "clip_model, transform = clip.load(name=clip_model_name, device=\"cuda\")\n",
    "clip_model = clip_model.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waterbird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we care about waterbird (label = 1), the most influential attributes are (reported Shapley value):\n",
      "[('ocean', tensor(0.3062)),\n",
      " ('lake natural', tensor(0.0713)),\n",
      " ('forest broadleaf', tensor(-0.1540)),\n",
      " ('bamboo forest', tensor(-0.1931))]\n"
     ]
    }
   ],
   "source": [
    "linear_model_path = \"../pytorch_cache/iclrsubmission/models/waterbird_linear_model.pt\"\n",
    "data_path = \"../../data/Waterbird/processed_attribute_dataset/attributes.jsonl\"\n",
    "state_dict = torch.load(linear_model_path)\n",
    "n_class = state_dict[\"fc.weight\"].shape[0]\n",
    "model = Linear(clip_model.visual.output_dim, n_class).cuda()\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "image_data = [\n",
    "    json.loads(line)\n",
    "    for line in open(\n",
    "        \"../../data/Waterbird/processed_attribute_dataset/attributes.jsonl\"\n",
    "    )\n",
    "]\n",
    "attributes = {\n",
    "    \"place\": set([x[\"attributes\"][\"place\"] for x in image_data]),\n",
    "    \"species\": set([x[\"attributes\"][\"species\"] for x in image_data]),\n",
    "}\n",
    "\n",
    "place_list = list(attributes[\"place\"])\n",
    "species_list = list(attributes[\"species\"])\n",
    "attribute_shapley = {}\n",
    "for place in place_list:\n",
    "    prompts = [f\"a photo of a {species}.\" for species in species_list] + [\n",
    "        f\"a photo of a {species} in the {place}.\" for species in species_list\n",
    "    ]\n",
    "    with torch.no_grad():\n",
    "        inputs = clip.tokenize(prompts).cuda()\n",
    "        embeddings = F.normalize(clip_model.encode_text(inputs))\n",
    "        probs = torch.softmax(model(embeddings), dim=1).cpu()\n",
    "\n",
    "    shapley = (probs[len(species_list) :, 1] - probs[: len(species_list), 1]).mean()\n",
    "    attribute_shapley[place] = shapley\n",
    "\n",
    "print(\n",
    "    \"If we care about waterbird (label = 1), the most influential attributes are (reported Shapley value):\"\n",
    ")\n",
    "pprint(sorted(attribute_shapley.items(), key=lambda x: x[1], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FairFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we care about gender (label = 1 female), the most influential attributes are (reported Shapley value):\n",
      "[('east asian', tensor(0.0266)),\n",
      " ('southeast asian', tensor(0.0119)),\n",
      " ('indian', tensor(0.0116)),\n",
      " ('latino hispanic', tensor(0.0046)),\n",
      " ('white', tensor(0.0040)),\n",
      " ('middle eastern', tensor(3.8439e-05)),\n",
      " ('black', tensor(-0.0327))]\n"
     ]
    }
   ],
   "source": [
    "linear_model_path = \"../pytorch_cache/iclrsubmission/models/fairface_linear_model.pt\"\n",
    "data_path = \"../../data/FairFace/processed_attribute_dataset/attributes.jsonl\"\n",
    "state_dict = torch.load(linear_model_path)\n",
    "n_class = state_dict[\"fc.weight\"].shape[0]\n",
    "model = Linear(clip_model.visual.output_dim, n_class).cuda()\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "image_data = [\n",
    "    json.loads(line)\n",
    "    for line in open(\"../../data/FairFace/processed_attribute_dataset/attributes.jsonl\")\n",
    "]\n",
    "age_description = {\n",
    "    \"0-2\": \"infant\",\n",
    "    \"3-9\": \"little\",\n",
    "    \"10-19\": \"teenage\",\n",
    "    \"20-29\": \"young\",\n",
    "    \"30-39\": \"adult\",\n",
    "    \"40-49\": \"middle-aged\",\n",
    "    \"50-59\": \"senior\",\n",
    "    \"60-69\": \"elderly\",\n",
    "    \"more than 70\": \"very old\",\n",
    "}\n",
    "attributes = {\n",
    "    \"race\": set(\n",
    "        [x[\"attributes\"][\"race\"].lower().replace(\"_\", \" \") for x in image_data]\n",
    "    ),\n",
    "    \"age\": set([age_description[x[\"attributes\"][\"age\"]] for x in image_data]),\n",
    "}\n",
    "\n",
    "race_list = list(attributes[\"race\"])\n",
    "age_list = list(attributes[\"age\"])\n",
    "attribute_shapley = {}\n",
    "for race in race_list:\n",
    "    prompts = (\n",
    "        [f\"a face of a {age} man.\" for age in age_list]\n",
    "        + [f\"a face of a {age} woman.\" for age in age_list]\n",
    "        + [f\"a face of a {race} {age} man.\" for age in age_list]\n",
    "        + [f\"a face of a {race} {age} woman.\" for age in age_list]\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        inputs = clip.tokenize(prompts).cuda()\n",
    "        embeddings = F.normalize(clip_model.encode_text(inputs))\n",
    "        probs = torch.softmax(model(embeddings), dim=1).cpu()\n",
    "\n",
    "    shapley = (probs[len(age_list) * 2 :, 1] - probs[: 2 * len(age_list), 1]).mean()\n",
    "    attribute_shapley[race] = shapley\n",
    "print(\n",
    "    \"If we care about gender (label = 1 female), the most influential attributes are (reported Shapley value):\"\n",
    ")\n",
    "pprint(sorted(attribute_shapley.items(), key=lambda x: x[1], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dSprites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we care about triangle (label = 1), the most influential attributes are (reported Shapley value):\n",
      "[('orange', tensor(0.3736)),\n",
      " ('red', tensor(-0.0470)),\n",
      " ('blue', tensor(-0.0784)),\n",
      " ('cyan', tensor(-0.0979)),\n",
      " ('pink', tensor(-0.1181)),\n",
      " ('green', tensor(-0.3321))]\n"
     ]
    }
   ],
   "source": [
    "linear_model_path = (\n",
    "    \"../pytorch_cache/iclrsubmission/models/dsprites_linear_model_2class.pt\"\n",
    ")\n",
    "data_path = \"../../data/TriangleSquare/processed_attribute_dataset/attributes.jsonl\"\n",
    "state_dict = torch.load(linear_model_path)\n",
    "n_class = state_dict[\"fc.weight\"].shape[0]\n",
    "model = Linear(clip_model.visual.output_dim, n_class).cuda()\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "attributes = {\n",
    "    \"scale\": {\"small\", \"medium\", \"large\"},\n",
    "    \"color\": {\"blue\", \"cyan\", \"green\", \"orange\", \"pink\", \"red\"},\n",
    "}\n",
    "\n",
    "scale_list = list(attributes[\"scale\"])\n",
    "color_list = list(attributes[\"color\"])\n",
    "attribute_shapley = {}\n",
    "for color in color_list:\n",
    "    prompts = (\n",
    "        [f\"a {scale} square.\" for scale in scale_list]\n",
    "        + [f\"a {scale} triangle.\" for scale in scale_list]\n",
    "        + [f\"a {scale} {color} square.\" for scale in scale_list]\n",
    "        + [f\"a {scale} {color} triangle.\" for scale in scale_list]\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        inputs = clip.tokenize(prompts).cuda()\n",
    "        embeddings = F.normalize(clip_model.encode_text(inputs))\n",
    "        probs = torch.softmax(model(embeddings), dim=1).cpu()\n",
    "\n",
    "    shapley = (probs[len(scale_list) * 2 :, 1] - probs[: 2 * len(scale_list), 1]).mean()\n",
    "    attribute_shapley[color] = shapley\n",
    "print(\n",
    "    \"If we care about triangle (label = 1), the most influential attributes are (reported Shapley value):\"\n",
    ")\n",
    "pprint(sorted(attribute_shapley.items(), key=lambda x: x[1], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dalle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf49421d02fb18daac2fe024769d7389ca36bccb970e26253e571efb021ca22f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
